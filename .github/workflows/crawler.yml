name: GitHub Crawler

# Trigger manually or on a schedule (every day at midnight)
on:
  workflow_dispatch:
  schedule:
    - cron: '0 0 * * *'

jobs:
  crawl:
    runs-on: ubuntu-latest

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_USER: postgres
          POSTGRES_DB: github
        options: >-
          --health-cmd="pg_isready -U postgres"
          --health-interval=5s
          --health-timeout=5s
          --health-retries=5
        ports:
          - 5432:5432  # Map container port to host

    env:
      # Use localhost because this job runs directly on the runner
      DATABASE_URL: postgresql://postgres:postgres@localhost:5432/github
      GITHUB_ACCESS_TOKEN: ${{ github.token }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: pip install -r requirements.txt

      - name: Wait for Postgres to be ready
        run: |
          echo "Waiting for Postgres..."
          until pg_isready -h localhost -U postgres -d github; do
            sleep 2
          done

      - name: Setup DB schema
        run: python -m scripts.setup_db

      - name: Crawl stars
        run: python -m src.app.main

      - name: Export database
        run: python -m scripts.export_data stars_history

      - name: Upload artifact
        uses: actions/upload-artifact@v4
        with:
          name: repo-stars
          path: output/*.csv
